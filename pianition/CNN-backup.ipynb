{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from os.path import isfile\n",
    "from PIL import Image as Img\n",
    "from data_util import *\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Input, Dense, TimeDistributed, LSTM, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Conv2D, BatchNormalization, Lambda\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras import backend\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras import regularizers\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded dataset from ../data/debug/\n",
      "(766, 128, 256)\n",
      "Building model...\n",
      "Training...\n",
      "Train on 766 samples, validate on 226 samples\n",
      "Epoch 1/70\n",
      "766/766 [==============================] - 4s 6ms/step - loss: 2.6788 - acc: 0.1475 - val_loss: 2.5937 - val_acc: 0.1814\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.18142, saving model to ../models/trail_Run01-2.59.hdf5\n",
      "Epoch 2/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 2.5648 - acc: 0.1841 - val_loss: 2.5928 - val_acc: 0.1416\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.18142\n",
      "Epoch 3/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 2.5463 - acc: 0.2285 - val_loss: 2.5819 - val_acc: 0.1770\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.18142\n",
      "Epoch 4/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 2.4961 - acc: 0.2285 - val_loss: 2.7648 - val_acc: 0.1681\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.18142\n",
      "Epoch 5/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 2.4586 - acc: 0.2311 - val_loss: 2.5948 - val_acc: 0.1858\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.18142 to 0.18584, saving model to ../models/trail_Run05-2.59.hdf5\n",
      "Epoch 6/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 2.3937 - acc: 0.2768 - val_loss: 3.0863 - val_acc: 0.1681\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.18584\n",
      "Epoch 7/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 2.3175 - acc: 0.3003 - val_loss: 2.8134 - val_acc: 0.1637\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.18584\n",
      "Epoch 8/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 2.2708 - acc: 0.3368 - val_loss: 3.9852 - val_acc: 0.1814\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.18584\n",
      "Epoch 9/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 2.3035 - acc: 0.3029 - val_loss: 2.8008 - val_acc: 0.1150\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.18584\n",
      "Epoch 10/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 2.2244 - acc: 0.3486 - val_loss: 2.6878 - val_acc: 0.1991\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.18584 to 0.19912, saving model to ../models/trail_Run10-2.69.hdf5\n",
      "Epoch 11/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 2.1741 - acc: 0.3616 - val_loss: 2.5943 - val_acc: 0.2035\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.19912 to 0.20354, saving model to ../models/trail_Run11-2.59.hdf5\n",
      "Epoch 12/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 2.1402 - acc: 0.3903 - val_loss: 3.0083 - val_acc: 0.1195\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.20354\n",
      "Epoch 13/70\n",
      "766/766 [==============================] - 2s 3ms/step - loss: 2.1815 - acc: 0.3420 - val_loss: 2.7891 - val_acc: 0.1903\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.20354\n",
      "Epoch 14/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 2.1697 - acc: 0.3916 - val_loss: 3.5191 - val_acc: 0.1814\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.20354\n",
      "Epoch 15/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 2.0972 - acc: 0.4138 - val_loss: 3.1392 - val_acc: 0.1770\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.20354\n",
      "Epoch 16/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 2.0179 - acc: 0.4204 - val_loss: 3.2535 - val_acc: 0.1726\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.20354\n",
      "Epoch 17/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 2.0349 - acc: 0.4204 - val_loss: 3.0820 - val_acc: 0.1681\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.20354\n",
      "Epoch 18/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 2.0490 - acc: 0.4060 - val_loss: 2.8870 - val_acc: 0.1195\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.20354\n",
      "Epoch 19/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 2.0186 - acc: 0.4204 - val_loss: 2.8230 - val_acc: 0.1903\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.20354\n",
      "Epoch 20/70\n",
      "766/766 [==============================] - 2s 3ms/step - loss: 1.9702 - acc: 0.4295 - val_loss: 3.2983 - val_acc: 0.1770\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.20354\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 21/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.8995 - acc: 0.4648 - val_loss: 3.2774 - val_acc: 0.1195\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.20354\n",
      "Epoch 22/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.9216 - acc: 0.4491 - val_loss: 2.6493 - val_acc: 0.1858\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.20354\n",
      "Epoch 23/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.8519 - acc: 0.4804 - val_loss: 2.7038 - val_acc: 0.2345\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.20354 to 0.23451, saving model to ../models/trail_Run23-2.70.hdf5\n",
      "Epoch 24/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.8749 - acc: 0.4739 - val_loss: 2.9848 - val_acc: 0.2212\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.23451\n",
      "Epoch 25/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.7687 - acc: 0.5326 - val_loss: 2.6590 - val_acc: 0.2212\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.23451\n",
      "Epoch 26/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.8157 - acc: 0.4909 - val_loss: 2.8256 - val_acc: 0.2168\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.23451\n",
      "Epoch 27/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.8707 - acc: 0.4739 - val_loss: 2.7996 - val_acc: 0.1903\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.23451\n",
      "Epoch 28/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.7406 - acc: 0.5196 - val_loss: 3.3541 - val_acc: 0.1903\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.23451\n",
      "Epoch 29/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.6919 - acc: 0.5300 - val_loss: 3.0134 - val_acc: 0.1460\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.23451\n",
      "Epoch 30/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.6718 - acc: 0.5379 - val_loss: 2.8256 - val_acc: 0.2035\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.23451\n",
      "Epoch 31/70\n",
      "766/766 [==============================] - 2s 3ms/step - loss: 1.6959 - acc: 0.5222 - val_loss: 2.8364 - val_acc: 0.2035\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.23451\n",
      "Epoch 32/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.6674 - acc: 0.5300 - val_loss: 2.9049 - val_acc: 0.2080\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.23451\n",
      "Epoch 33/70\n",
      "766/766 [==============================] - 2s 3ms/step - loss: 1.6303 - acc: 0.5796 - val_loss: 2.8057 - val_acc: 0.2478\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.23451 to 0.24779, saving model to ../models/trail_Run33-2.81.hdf5\n",
      "Epoch 34/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.6400 - acc: 0.5483 - val_loss: 3.1931 - val_acc: 0.1770\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.24779\n",
      "Epoch 35/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.6804 - acc: 0.5157 - val_loss: 4.4528 - val_acc: 0.1770\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.24779\n",
      "Epoch 36/70\n",
      "766/766 [==============================] - 2s 3ms/step - loss: 1.6864 - acc: 0.5379 - val_loss: 3.0619 - val_acc: 0.1327\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.24779\n",
      "Epoch 37/70\n",
      "766/766 [==============================] - 2s 3ms/step - loss: 1.6096 - acc: 0.5587 - val_loss: 3.0685 - val_acc: 0.1947\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.24779\n",
      "Epoch 38/70\n",
      "766/766 [==============================] - 2s 3ms/step - loss: 1.6044 - acc: 0.5444 - val_loss: 4.1186 - val_acc: 0.1681\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.24779\n",
      "Epoch 39/70\n",
      "766/766 [==============================] - 2s 3ms/step - loss: 1.5514 - acc: 0.5875 - val_loss: 4.5259 - val_acc: 0.1460\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.24779\n",
      "Epoch 40/70\n",
      "766/766 [==============================] - 2s 3ms/step - loss: 1.5230 - acc: 0.5940 - val_loss: 4.0145 - val_acc: 0.0973\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.24779\n",
      "Epoch 41/70\n",
      "766/766 [==============================] - 2s 3ms/step - loss: 1.5097 - acc: 0.6031 - val_loss: 3.2566 - val_acc: 0.1681\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.24779\n",
      "Epoch 42/70\n",
      "766/766 [==============================] - 2s 3ms/step - loss: 1.4775 - acc: 0.6057 - val_loss: 4.1138 - val_acc: 0.1637\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.24779\n",
      "Epoch 43/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766/766 [==============================] - 2s 2ms/step - loss: 1.5236 - acc: 0.6123 - val_loss: 3.2416 - val_acc: 0.1681\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.24779\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 44/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.4533 - acc: 0.6018 - val_loss: 2.9760 - val_acc: 0.2301\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.24779\n",
      "Epoch 45/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.4547 - acc: 0.6123 - val_loss: 3.6146 - val_acc: 0.1681\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.24779\n",
      "Epoch 46/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.4004 - acc: 0.6305 - val_loss: 4.8923 - val_acc: 0.1726\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.24779\n",
      "Epoch 47/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.4279 - acc: 0.6110 - val_loss: 3.3473 - val_acc: 0.1991\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.24779\n",
      "Epoch 48/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.3820 - acc: 0.6279 - val_loss: 3.3075 - val_acc: 0.1637\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.24779\n",
      "Epoch 49/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.3606 - acc: 0.6384 - val_loss: 3.6572 - val_acc: 0.1726\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.24779\n",
      "Epoch 50/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.3363 - acc: 0.6632 - val_loss: 4.1854 - val_acc: 0.1991\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.24779\n",
      "Epoch 51/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.3496 - acc: 0.6462 - val_loss: 3.4133 - val_acc: 0.2301\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.24779\n",
      "Epoch 52/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.3210 - acc: 0.6540 - val_loss: 3.2917 - val_acc: 0.1549\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.24779\n",
      "Epoch 53/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.3110 - acc: 0.6527 - val_loss: 3.6095 - val_acc: 0.2080\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.24779\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 54/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.2777 - acc: 0.6619 - val_loss: 3.3378 - val_acc: 0.2345\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.24779\n",
      "Epoch 55/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.2679 - acc: 0.6723 - val_loss: 3.4941 - val_acc: 0.1947\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.24779\n",
      "Epoch 56/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.2243 - acc: 0.6867 - val_loss: 3.3838 - val_acc: 0.2257\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.24779\n",
      "Epoch 57/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.2572 - acc: 0.6775 - val_loss: 3.6084 - val_acc: 0.1814\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.24779\n",
      "Epoch 58/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.3034 - acc: 0.6593 - val_loss: 4.3256 - val_acc: 0.2080\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.24779\n",
      "Epoch 59/70\n",
      "766/766 [==============================] - 2s 3ms/step - loss: 1.2422 - acc: 0.6841 - val_loss: 3.4723 - val_acc: 0.2168\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.24779\n",
      "Epoch 60/70\n",
      "766/766 [==============================] - 2s 3ms/step - loss: 1.2131 - acc: 0.6815 - val_loss: 3.4159 - val_acc: 0.1903\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.24779\n",
      "Epoch 61/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.2045 - acc: 0.6749 - val_loss: 3.2203 - val_acc: 0.1726\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.24779\n",
      "Epoch 62/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.1329 - acc: 0.7206 - val_loss: 3.5630 - val_acc: 0.2168\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.24779\n",
      "Epoch 63/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.2216 - acc: 0.6984 - val_loss: 3.8272 - val_acc: 0.2301\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.24779\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 64/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.2107 - acc: 0.6958 - val_loss: 3.3972 - val_acc: 0.2035\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.24779\n",
      "Epoch 65/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.1828 - acc: 0.7076 - val_loss: 3.4286 - val_acc: 0.2080\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.24779\n",
      "Epoch 66/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.1458 - acc: 0.7128 - val_loss: 3.5623 - val_acc: 0.1947\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.24779\n",
      "Epoch 67/70\n",
      "766/766 [==============================] - 2s 3ms/step - loss: 1.1558 - acc: 0.7167 - val_loss: 3.3596 - val_acc: 0.1814\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.24779\n",
      "Epoch 68/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.1545 - acc: 0.7037 - val_loss: 3.9157 - val_acc: 0.2257\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.24779\n",
      "Epoch 69/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.1349 - acc: 0.7102 - val_loss: 3.4397 - val_acc: 0.1814\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.24779\n",
      "Epoch 70/70\n",
      "766/766 [==============================] - 2s 2ms/step - loss: 1.1024 - acc: 0.7285 - val_loss: 3.5915 - val_acc: 0.2168\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.24779\n",
      "DONE!!!\n"
     ]
    }
   ],
   "source": [
    "dir = \"../data/debug/\"\n",
    "ds = load_dataset(dir)\n",
    "x_train, y_train = ds.get_train_full()\n",
    "x_val, y_val = ds.get_val_full()\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 12\n",
    "\n",
    "N_LAYERS = 3\n",
    "FILTER_LENGTH = 5\n",
    "CONV_FILTER_COUNT = 56\n",
    "BATCH_SIZE = 32\n",
    "LSTM_COUNT = 96\n",
    "EPOCH_COUNT = 70\n",
    "NUM_HIDDEN = 64\n",
    "L2_regularization = 0.001\n",
    "\n",
    "\n",
    "def conv_recurrent_model_build(model_input):\n",
    "    print('Building model...')\n",
    "    layer = model_input\n",
    "\n",
    "    ### 3 1D Convolution Layers\n",
    "    for i in range(N_LAYERS):\n",
    "        # give name to the layers\n",
    "        layer = Conv1D(\n",
    "            filters=CONV_FILTER_COUNT,\n",
    "            kernel_size=FILTER_LENGTH,\n",
    "            kernel_regularizer=regularizers.l2(\n",
    "                L2_regularization),  # Tried 0.001\n",
    "            name='convolution_' + str(i + 1))(layer)\n",
    "        layer = BatchNormalization(momentum=0.9)(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        layer = MaxPooling1D(2)(layer)\n",
    "        layer = Dropout(0.4)(layer)\n",
    "\n",
    "    ## LSTM Layer\n",
    "    layer = LSTM(LSTM_COUNT, return_sequences=False)(layer)\n",
    "    layer = Dropout(0.4)(layer)\n",
    "\n",
    "    ## Dense Layer\n",
    "    layer = Dense(NUM_HIDDEN,\n",
    "                  kernel_regularizer=regularizers.l2(L2_regularization),\n",
    "                  name='dense1')(layer)\n",
    "    layer = Dropout(0.4)(layer)\n",
    "\n",
    "    ## Softmax Output\n",
    "    layer = Dense(num_classes)(layer)\n",
    "    layer = Activation('softmax', name='output_realtime')(layer)\n",
    "    model_output = layer\n",
    "    model = Model(model_input, model_output)\n",
    "\n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    #print(model.summary())\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(x_train, y_train, x_val, y_val, checkpoint_name):\n",
    "\n",
    "    print(x_train.shape)\n",
    "    n_features = x_train[0].shape[0]\n",
    "    input_shape = (n_features, 256)\n",
    "    model_input = Input(input_shape, name='input')\n",
    "\n",
    "    model = conv_recurrent_model_build(model_input)\n",
    "\n",
    "    tb_callback = TensorBoard(log_dir='./logs/4',\n",
    "                              histogram_freq=1,\n",
    "                              batch_size=32,\n",
    "                              write_graph=True,\n",
    "                              write_grads=False,\n",
    "                              write_images=False,\n",
    "                              embeddings_freq=0,\n",
    "                              embeddings_layer_names=None,\n",
    "                              embeddings_metadata=None)\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint('../models/'+checkpoint_name+'{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "                                          monitor='val_acc',\n",
    "                                          verbose=1,\n",
    "                                          save_best_only=True,\n",
    "                                          mode='max')\n",
    "\n",
    "    reducelr_callback = ReduceLROnPlateau(monitor='val_acc',\n",
    "                                          factor=0.5,\n",
    "                                          patience=10,\n",
    "                                          min_delta=0.01,\n",
    "                                          verbose=1)\n",
    "\n",
    "    callback_list = [checkpoint_callback, reducelr_callback]\n",
    "    \n",
    "#     if(os.path.isfile('../models/'+checkpoint_name+'.hdf5')):\n",
    "#         print(\"Weights already exists. Change Name!\")\n",
    "#         return\n",
    "\n",
    "    # Fit the model and get training history.\n",
    "    print('Training...')\n",
    "    history = model.fit(x_train,\n",
    "                        y_train,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        epochs=EPOCH_COUNT,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        callbacks=callback_list,\n",
    "                        verbose=1)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "# Better to change checkpoint name before run\n",
    "model, history = train_model(np.array(x_train), np.array(y_train),\n",
    "                             np.array(x_val), np.array(y_val),\n",
    "                            \"trail_Run\")\n",
    "print(\"DONE!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#voil√†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHUFFLE_BUFFER = 1000\n",
    "BATCH_SIZE = 16\n",
    "NUM_CLASSES = 41\n",
    "\n",
    "# Create a description of the features.  \n",
    "feature_description = {\n",
    "    'feature0': tf.FixedLenFeature([32768], tf.float32),\n",
    "    'feature1': tf.FixedLenFeature([1], tf.int64)\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "  # Parse the input tf.Example proto using the dictionary above.\n",
    "    parsed_example = tf.parse_single_example(example_proto, feature_description)\n",
    "    parsed_example[\"feature0\"] = tf.transpose(tf.reshape(parsed_example['feature0'], (256,128)))\n",
    "    return parsed_example\n",
    "\n",
    "def create_dataset(filepath):\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(filepath)\n",
    "    \n",
    "    dataset = dataset.map(_parse_function) #, num_parallel_calls=8)\n",
    "    \n",
    "    # This dataset will go on forever\n",
    "    dataset = dataset.repeat()\n",
    "    \n",
    "    # Set the number of datapoints you want to load and shuffle \n",
    "    dataset = dataset.shuffle(SHUFFLE_BUFFER)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    \n",
    "    # Create an iterator\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    # Create your tf representation of the iterator\n",
    "    feature = iterator.get_next()\n",
    "    #print(feature)\n",
    "    lmfcc = feature[\"feature0\"]\n",
    "    label = feature[\"feature1\"]\n",
    "    \n",
    "    # Bring your picture back in shape\n",
    "    lmfcc = tf.reshape(lmfcc, [-1,128, 256])\n",
    "    \n",
    "    # Create a one hot array for your labels\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    print(lmfcc.shape)\n",
    "    print(label.shape)\n",
    "\n",
    "    return lmfcc, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 128, 256)\n",
      "(?, 1, 41)\n"
     ]
    }
   ],
   "source": [
    "_ = create_dataset(\"../data/debug/sample.tfrecords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
